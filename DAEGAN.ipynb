{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN0/5pYMfDbpkHjixv0B1lV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import PIL\n","import urllib\n","from torchvision import datasets, transforms"],"metadata":{"id":"JrA2AidMUUzr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DAE(nn.module):\n","  def __init__(self, inputDim, k):\n","    # they use \"same\" padding meaning the dimension shouldn't change between layers\n","    # have to choose padding value once we know our image dimension\n","    self.encoder = nn.Sequential(\n","        nn.Conv2d(inputDim, 64, 3, 2, ),\n","        nn.BatchNorm2d(64),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.ConvTranspose2d(64, 128, 3, 2, ),\n","        nn.BatchNorm2d(128),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.ConvTranspose2d(128, 256, 3, 2, ),\n","        nn.BatchNorm2d(256),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.ConvTranspose2d(256, 512, 3, 2, ),\n","        nn.BatchNorm2d(512),\n","        nn.LeakyReLU(0.2)\n","    )\n","\n","    self.F = nn.Sequential(\n","        nn.Conv2d(__, 2*k, 3, 2, ),\n","        nn.BatchNorm2d(2*k),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.ConvTranspose2d(2*k, 4*k, 3, 2, ),\n","        nn.BatchNorm2d(4*k),\n","        nn.LeakyReLU(0.2)\n","    )\n","\n","    def forward(self, x):\n","      encode = self.encoder(x)\n","      outF = self.F(encode, features)\n","      xy = FC_location(__)\n","      mask = get_mask(__)\n","      mask *= x\n","      encodeMask = self.encoder(mask)\n","      ___ = ____\n","      return encodeMask, ___\n",""],"metadata":{"id":"u8WuoB-7XCPh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Gen(nn.Module):\n","  def __init__(self, inputDim):\n","    super().__init__()\n","    # they use \"same\" padding meaning the dimension shouldn't change between layers\n","    # have to choose padding value once we know our image dimension\n","    self.model = nn.Sequential(\n","      nn.ConvTranspose2d(inputDim, 256, 5, 1, ),\n","      nn.LeakyReLU(0.2),\n","\n","      nn.ConvTranspose2d(256, 128, 5, 1, ),\n","      nn.BatchNorm2d(128),\n","      nn.LeakyReLU(0.2),\n","\n","      nn.ConvTranspose2d(128, 64, 5, 1, ),\n","      nn.BatchNorm2d(64),\n","      nn.LeakyReLU(0.2),\n","\n","      nn.ConvTranspose2d(64, 3, 5, 1, ),\n","      nn.Tanh())\n","\n","  def forward(self, x):\n","    return self.model(x)"],"metadata":{"id":"LWXVUVE98W2O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DiscSource(nn.Module):\n","  def __init__(self, inputDim):\n","    super().__init__()\n","    # they use \"same\" padding meaning the dimension shouldn't change between layers\n","    # have to choose padding value once we know our image dimension\n","    self.model = nn.Sequential(\n","      nn.Conv2d(inputDim, 64, 3, 2, ),\n","      nn.BatchNorm2d(64),\n","      nn.LeakyReLU(0.2),\n","\n","      nn.ConvTranspose2d(64, 128, 3, 2, ),\n","      nn.BatchNorm2d(128),\n","      nn.LeakyReLU(0.2),\n","\n","      nn.ConvTranspose2d(128, 256, 3, 2, ),\n","      nn.BatchNorm2d(256),\n","      nn.LeakyReLU(0.2),\n","\n","      nn.ConvTranspose2d(256, 512, 3, 2, ),\n","      nn.BatchNorm2d(512),\n","      nn.LeakyReLU(0.2),\n","\n","      nn.Linear(512, 1),\n","      nn.Sigmoid())\n","\n","  def forward(self, x):\n","    return self.model(x)"],"metadata":{"id":"2f4sSNHw8i7u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train():\n","\n","  return"],"metadata":{"id":"NRFfGB1BWsaJ","executionInfo":{"status":"ok","timestamp":1690511818331,"user_tz":240,"elapsed":129,"user":{"displayName":"Tyler Yan","userId":"04796090833687371116"}}},"execution_count":2,"outputs":[]}]}