{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import urllib\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "JrA2AidMUUzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_data = datasets.MNIST('data', train=True, download=True)\n",
        "mnist_data = list(mnist_data)\n",
        "mnist_train = mnist_data[:5000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fzeq1W_vletN",
        "outputId": "04ab37d2-c87b-4a5f-8015-d630e845cfe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 95577226.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 79225437.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 29252193.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 11766849.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "7-oAPtorn9C5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_to_tensor = transforms.ToTensor()"
      ],
      "metadata": {
        "id": "21ntGqdSolH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NArlPo-wI7Xy"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.model = nn.Sequential(\n",
        "    nn.Linear(28*28, 300),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Linear(300, 100),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Linear(100, 1))\n",
        "  def forward(self, x):\n",
        "    x = x.view(x.size(0), -1)\n",
        "    out = self.model(x)\n",
        "    return out.view(x.size(0))\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "    self.model = nn.Sequential(\n",
        "    nn.Linear(100, 300),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Linear(300, 28*28),\n",
        "    nn.Sigmoid())\n",
        "  def forward(self, x):\n",
        "    out = self.model(x).view(x.size(0), 1, 28, 28)\n",
        "    return out.view(x.size(0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_discriminator(discriminator, generator, images):\n",
        "  batch_size = img_to_tensor(images).size(0)\n",
        "  noise = torch.randn(batch_size, 100)\n",
        "  fake_images = generator(noise)\n",
        "  inputs = torch.cat([images, fake_images])\n",
        "  labels = torch.cat([torch.zeros(batch_size), # Real\n",
        "  torch.ones(batch_size)]) # Fake\n",
        "  outputs = discriminator(inputs)\n",
        "  loss = criterion(outputs, labels)\n",
        "  return outputs, loss\n"
      ],
      "metadata": {
        "id": "Z7F8hteaSw2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_generator(discriminator, generator, images):\n",
        "  batch_size = images.size(0)\n",
        "  noise = torch.randn(batch_size, 100)\n",
        "  fake_images = generator(noise)\n",
        "  outputs = discriminator(fake_images)\n",
        "  # Only looks at fake outputs\n",
        "  # gets rewarded if we fool the discriminator!\n",
        "  labels = torch.zeros(batch_size)\n",
        "  loss = criterion(outputs, labels)\n",
        "  return fake_images, loss\n"
      ],
      "metadata": {
        "id": "x79A8lIAS19W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(discriminator, generator, lr, epochs, train_loader  ):\n",
        "  torch.manual_seed(42)\n",
        "  optimizerDisc = optim.Adam(discriminator.parameters(), lr = lr)\n",
        "  optimizerGen = optim.Adam(generator.parameters(), lr = lr)\n",
        "\n",
        "  Gtrain_acc, Gval_acc, iters, Gtrain_loss, Gval_loss = [], [], [], [], []\n",
        "  Dtrain_acc, Dval_acc, iters, Dtrain_loss, Dval_loss = [], [], [], [], []\n",
        "  genImgs = []\n",
        "\n",
        "  start_time = time.time()\n",
        "  for epoch in range(epochs):\n",
        "    Gtotal_train_loss = 0.0\n",
        "    Dtotal_train_loss = 0.0\n",
        "    iteration = 0\n",
        "    for imgs, __ in train_loader:\n",
        "      outputD, lossD = train_discriminator(discriminator, generator, imgs)\n",
        "      lossD.backward()\n",
        "      Dtotal_train_loss += lossD.item()\n",
        "      optimizerDisc.step()\n",
        "      optimizerDisc.zero_grad()\n",
        "\n",
        "      outputG, lossG = train_generator(discriminator, generator, imgs)\n",
        "      lossG.backward()\n",
        "      Gtotal_train_loss += lossG.item()\n",
        "      optimizerGen.step()\n",
        "      optimizerGen.zero_grad()\n",
        "      iteration += 1\n",
        "\n",
        "    Gtrain_loss.append(float(Gtotal_train_loss) / (iteration + 1))\n",
        "    #Gval_loss.append(evaluate(model, valid_loader, criterion))\n",
        "    Dtrain_loss.append(float(Dtotal_train_loss) / (iteration + 1))\n",
        "\n",
        "    print((\"Epoch {}: Gen Train loss: {}, Disc Train loss: {}\").format(\n",
        "               # + \"Gen Validation loss: {}, Disc Validation loss: {}\").format(\n",
        "                   epoch + 1,\n",
        "                   #train_acc[epoch],\n",
        "                   Gtrain_loss[epoch],\n",
        "                   Dtrain_loss[epoch]))\n",
        "                   #val_acc[epoch],\n",
        "                   #val_loss[epoch]))\n",
        "    # Save the current model (checkpoint) to a file\n",
        "    #model_path = get_model_name(model.name, learning_rate, epoch)\n",
        "    #torch.save(model.state_dict(), model_path)\n",
        "  print('Finished Training')\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "  print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))\n",
        "  #print((\"Final Train Accuracy: {}, |\"+\n",
        "  #             \"Final Validation Accuracy: {}\").format(\n",
        "  #                 train_acc[-1],\n",
        "  #                 val_acc[-1],))\n",
        "#return train_acc, train_loss, val_acc, val_loss\n",
        "  noise = torch.randn(64, 100)\n",
        "  fake_imgs = generator(noise).detach()\n",
        "  genImgs.append(fake_imgs)\n",
        "  return Gtrain_loss, Dtrain_loss, genImgs\n",
        "\n",
        "def plot(Gtrain_loss, Dtrain_loss):\n",
        "    # Plotting\n",
        "    plt.title(\"Gen Train Loss vs Disc Train Loss\")\n",
        "    n = len(Gtrain_loss) # number of epochs\n",
        "    plt.plot(range(1,n+1), Gtrain_loss, label=\"Gen Train\")\n",
        "    plt.plot(range(1,n+1), Dtrain_loss, label=\"Disc Train\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "def check(dataLoader, genImgs):\n",
        "  real = next(iter(dataLoader))\n",
        "\n",
        "  plt.figure(figsize = (15,15))\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.axis(\"off\")\n",
        "  plt.title(\"Real\")\n",
        "  plt.imshow(np.transpose(real[0], (1,2,0)))\n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.axis(\"off\")\n",
        "  plt.title(\"Fake\")\n",
        "  plt.imshow(np.transpose(genImgs[0], (1,2,0)))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "1rOogssIWpIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator()\n",
        "discriminator = Discriminator()"
      ],
      "metadata": {
        "id": "ifcgk89_SJ6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Gtrain_loss, Dtrain_loss, genImgs = train(discriminator, generator, 0.001, 5, mnist_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "arwghmyVoA8g",
        "outputId": "9450b27b-b2a5-4a6d-d52b-66ed81c44e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-694efa38c621>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenImgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-afc829786517>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(discriminator, generator, lr, epochs, train_loader)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m       \u001b[0moutputD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m       \u001b[0mlossD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0mDtotal_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlossD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-a90ca1347008>\u001b[0m in \u001b[0;36mtrain_discriminator\u001b[0;34m(discriminator, generator, images)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mfake_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_images\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   labels = torch.cat([torch.zeros(batch_size), # Real\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-7be87bf709e1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[1]' is invalid for input of size 784"
          ]
        }
      ]
    }
  ]
}