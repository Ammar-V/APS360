{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9HPJLO0KnkH"
      },
      "outputs": [],
      "source": [
        "# bs = 32\n",
        "# d_latent = 512\n",
        "# imgsz = 32\n",
        "# lr = 1e-3\n",
        "# map lr = 1e-5\n",
        "# training steps = 150k\n",
        "\n",
        "def train_discriminator(gen, disc, inputs, latent_dim, criterion):\n",
        "  batchSize = inputs.size(0)\n",
        "\n",
        "  real_images = inputs.to(device)\n",
        "  realLabels = torch.ones(batchSize, device = device)\n",
        "\n",
        "  noise = torch.randn(batchSize, latent_dim, 1, 1, device = device)\n",
        "  w = ___\n",
        "  fake_images = gen.forward(w, noise)\n",
        "  fakeLabels = torch.zeros(batchSize, device = device)\n",
        "\n",
        "  discPredReal = disc.forward(real_images).view(-1)\n",
        "  realLoss = criterion(discPredReal, realLabels) #they use different loss function (wasserstein)\n",
        "\n",
        "  discPredFake = disc.forward(fake_images).view(-1)\n",
        "  fakeLoss = criterion(discPredFake, fakeLabels) #they use different loss function (wasserstein)\n",
        "\n",
        "  discLoss = 0.5 * (realLoss + fakeLoss)\n",
        "  return realLabels, fakeLabels, fake_images, discLoss, discPredReal\n",
        "\n",
        "def train_generator(gen, disc, inputs, realLabels, criterion):\n",
        "  batchSize = inputs.size(0)\n",
        "  realLabels = torch.ones(batchSize, device = device)\n",
        "\n",
        "  noise = torch.randn(batchSize, latent_dim, 1, 1, device = device)\n",
        "  w = ___\n",
        "  fake_images = gen.forward(w, noise)\n",
        "  discPredFake = model.discForward(fake_images).view(-1)\n",
        "  genLoss = criterion(discPredFake, realLabels) # they use different loss function (mean)\n",
        "\n",
        "  return genLoss, discPredFake\n",
        "\n",
        "def train_network(model, latent_dim, device, trainLoader, num_epochs, lrGAN, lrMap):\n",
        "    gen_optimizer =  optim.Adam(generator.parameters(), lr= lrGAN, weight_decay=1e-3)\n",
        "    disc_optimizer =  optim.Adam(discriminator.parameters(), lr=lrGAN, weight_decay=1e-3)\n",
        "    map_optimizer = optim.Adam(mapping.parameters(), lr = lrMap, weight_decay = 1e-3)\n",
        "\n",
        "  # Training metrics\n",
        "    train_gen_loss = []\n",
        "    train_disc_loss = []\n",
        "    train_disc_real_acc = []\n",
        "    train_disc_fake_acc = []\n",
        "    newImgs = []\n",
        "\n",
        "    best_train_err = 1000\n",
        "    best_val_err = 1000\n",
        "\n",
        "    ########## SENDING TO CUDA ############\n",
        "    if cuda:\n",
        "        generator = generator.to('cuda:0')\n",
        "        discriminator = discriminator.to('cuda:0')\n",
        "        mapping = mapping.to('cuda:0')\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        iteration = 0\n",
        "\n",
        "        disc_optimizer.zero_grad()\n",
        "        for imgs, _ in trainLoader:\n",
        "\n",
        "\n",
        "            realLabels, fakeLabels, fake_images, discLoss, discPredReal = train_discriminator(generator, discriminator, imgs, latent_dim, criterion)\n",
        "\n",
        "            discLoss.backward()\n",
        "\n",
        "        train_disc_loss.append(discLoss.item())\n",
        "        disc_optimizer.step()\n",
        "\n",
        "        gen_optimizer.zero_grad()\n",
        "        map_optimizer.zero_grad()\n",
        "\n",
        "        for imgs, _ in trainLoader\n",
        "            genLoss, discPredFake = train_generator(generator, discriminator, imgs, realLabels, criterion)\n",
        "            genLoss.backward()\n",
        "            train_gen_loss.append(genLoss.item())\n",
        "\n",
        "        gen_optimizer.step()\n",
        "        map_optimizer.step()\n",
        "\n",
        "        predReal = torch.where(discPredReal.detach() > 0.0, 1.0, 0.0)\n",
        "        predFake = torch.where(discPredFake.detach() > 0.0, 1.0, 0.0)\n",
        "        accReal = (predReal == realLabels).float().mean() * 100\n",
        "        accFake = (predFake == fakeLabels).float().mean() * 100\n",
        "\n",
        "\n",
        "\n",
        "        train_disc_real_acc.append(accReal.item())\n",
        "        train_disc_fake_acc.append(accFake.item())\n",
        "\n",
        "        iteration += 1\n",
        "\n",
        "        if(iteration % interval == 0):\n",
        "            print(\"Epoch: %03d/%03d | Batch %03d/%03d | Gen/Disc Loss: %.4f/%.4f\"\n",
        "                        % (epoch + 1, num_epochs, iteration, len(trainLoader),\n",
        "                            genLoss.item(), discLoss.item()))\n",
        "        newImgs.append(torchvision.utils.make_grid(fake_images, padding = 2, normalzie = True))\n",
        "        print(\"Time elapsed: %.2f min\" % ((time.time() - start_time) / 60))\n",
        "\n",
        "    print('Finished Training')\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))\n",
        "\n",
        "    return train_gen_loss, train_disc_loss, train_disc_real_acc, train_disc_fake_acc, newImgs"
      ]
    }
  ]
}